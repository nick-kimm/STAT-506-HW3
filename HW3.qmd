---
title: "HW3"
author: "Nick Kim"
format:
  html:
    embed-resources: true
---

Link to my [github](https://github.com/nick-kimm/STAT-506-HW3) repository. I lost my original version control project so if you want to see my commits up until my initial commit in the linked reposititory check out this link:  [link](https://github.com/nick-kimm/HW3)

## Question 1

#Part a: 
Reading Data Files 
```{r}
library(haven)

v_file <- "/Users/nicholaskim/Documents/STAT 506/HW3/VIX_D.XPT"
vision <- read_xpt(v_file)

d_file <- "/Users/nicholaskim/Documents/STAT 506/HW3/DEMO_D.XPT"
demo <- read_xpt(d_file)
```

Merging into one dataframe:
```{r}
mdata<-merge(vision,demo)
#Checking if its a data frame
print(is.data.frame(mdata))
#Showing it reduced the size of the dataframe to only that matched
print(c(nrow(demo),nrow(mdata)))
```

#Part b:
Proportion of respondents in each 10 year bands. From the DEMO doc we know all possible range of values is 0-85 yrs
```{r}
colnames(mdata)[c(15,62,65,61,78)]<-c("vision","age","race","gender","pir")

#remove all rows where there is NA or 9 (don't know) for if the respondent wears glasses/contacts
mdata<-mdata[is.na(mdata$vision)!=TRUE & mdata$vision!=9,]

#this will store the total count of individuals in each 10 year band into one vector
tages <- vector(length=9)
#this will store the total count of individuals who wear either glasses or contacts
gccount <- vector(length=9)
#this will store the percentage that wear glasses or contacts in there respective age group
pgc <- vector(length=9)

for (i in 1:9){
  tages[i] <- nrow(mdata[(mdata$age<(i*10)&mdata$age>((i-1)*10)),])
  gccount[i] <- nrow(mdata[mdata$vision==1&((mdata$age<(i*10)&mdata$age>((i-1)*10))),])
  pgc[i] <- (gccount[i]/tages[i])*100
}
```



```{r}
library(knitr)
library(kableExtra)

prop<-t(data.frame("Num Wears Glasses/Contacts"=format(round(gccount, 0), nsmall = 0),"Total in Age Group"=format(round(tages, 0), nsmall = 0),"Per Who Wear Glasses/Contacts"=format(round(pgc, 2), nsmall = 2)))

colnames(prop)<-c("0-9","10-19","20-29","30-39","40-49","50-59","60-69","70-79","80-89")

prop%>%
  kbl(caption = "Percentage of Respondents Who Wear Glasses/Contacts in 10 yr Bands")%>%
  kable_paper()%>%
  add_header_above(c("Ages"=10))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


#Part c:
Fitting logistic regression models:

Model 1:
Just Age as predictor

First we'll be changing the value of VIQ220 (whether they wear glasses/contacts) to a bionomial variable since GLM requires it to be in between the values of 0 to 1.
```{r}
mdata$vision <- ifelse(mdata$vision==2,0,1)
```

Running the Logistic Regression Model
```{r}
mod1<-glm(vision~age,data=mdata,family=binomial)
summary(mod1)
```

Model 2:
Age, Race, and Gender as predictor variables
```{r}
mod2<-glm(vision~age+race+gender,data=mdata,family=binomial)
summary(mod2)
```

Model 3:
Age, Race, Gender, and Poverty Income Ratio as predictor variables
```{r}
mod3<-glm(vision~age+race+gender+pir,data=mdata,family=binomial)
summary(mod3)
```
Creating one table output

Storing all values for each model in separate vectors to try and create a similar output as in stargazer package. First couple of values will be the coefficients and if there are missing values will store as "-". Followed by sample size and the calculated Pseudo R^2: 1-(null deviance/residual deviance) and lastly AIC
```{r}
#all model 1 values
mod1_values <- c(round(unname(mod1$coefficients),4),"-","-","-",
                 nobs(mod1),
                 round(1-(summary(mod1)$deviance/summary(mod1)$null.deviance),2),
                 round(summary(mod1)$aic,2))
mod2_values <- c(round(unname(mod2$coefficients),4),"-",
                 nobs(mod2),
                 round(1-(summary(mod2)$deviance/summary(mod2)$null.deviance),2),
                 round(summary(mod2)$aic,2))
mod3_values <- c(round(unname(mod3$coefficients),4),
                 nobs(mod3),
                 round(1-(summary(mod3)$deviance/summary(mod3)$null.deviance),2),
                 round(summary(mod3)$aic,2))

summary_t<-data.frame("Model 1"=mod1_values,"Model 2"=mod2_values,"Model 3"=mod3_values)
rownames(summary_t)<-c("Intercept","Age","Race","Gender","PIC","Sample Size","Pseduo-R^2","AIC")
summary_t%>%
  kbl(caption = "Summary Table for Each Model")%>%
  kable_paper()%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

#Part d: 

Test for whether the odds in vision between genders differs. This is found in our summary table, but specifically the line for our variable RIAGENDR or Gender. 
```{r}
summary(mod3)
```
From above we can see that the p-value of our variable RIAGENDR is less than our critical value of 0.05. This means there is enough evidence to say that there is a statistically significant difference in vision between men and women. 

Test whether the proportion of gender for vision differs. 

First creating a table of gender and vision. This will count how many individuals are Male (1) who wear Glasses/Contacts and don't, and same for Female (2)
```{r}
gen_vis<-table(mdata$gender,mdata$vision)
gen_vis
```
Running a Chi-squared test
```{r}
chisq.test(gen_vis)
```
From the output above we can see that the p-value is less than our critical value of 0.05. This means that there is enough evidence to say that there is a significant different in the proportion of genders. 

##Question 2:

Establish connect to data
```{r}
library(DBI) 
library(RSQLite)
movies<-dbConnect(SQLite(),"/Users/nicholaskim/Documents/STAT 506/HW3/sakila_master.db")
```

Defining a helper function
```{r}
#' db function
#'This function will shorten the function name we will call when using dbConnect for ease of use for the user
#' @param connection 
#' @param query 
#'
#' @return output from dbConnect function
gg <- function(connection,query){
  dbGetQuery(connection,query)
}
```

#Part a:
What year is the oldest movie from, and how many movies were released in that year?
```{r}
dbListTables(movies)
dbListFields(movies,"film")
```

```{r}
gg(movies,"
   SELECT release_year, COUNT(film_id) AS count
    FROM film
   GROUP BY release_year
   ORDER BY release_year
   ")
```
#Part b:
What genre of movie is the least common in the data, and how many movies are of this genre?

Using data.frame operations after pulling requried tables using SQL:
```{r}
dbListFields(movies,"film_category")

movie_genres<-gg(movies,"
   SELECT *
   FROM film_category
   ")

genres<-gg(movies,"
   SELECT *
   FROM category")

#This is a frequency table based off category id 
print(table(movie_genres$category_id))

#This will extract the id associated with the minimum value. In this case we should expect it to be 12
mgen<-which.min(table(movie_genres$category_id))

#This will put a name to this category id
genres[genres$category_id==mgen,2]
print(min(table(movie_genres$category_id)))
```
From above we can see that the least common movie genre is Music of which there are 51 of in this dataset. 

Using only SQL:
```{r}
gg(movies,"
   SELECT c.name, count(fc.category_id) AS count
    FROM film_category as fc
      LEFT JOIN 
      (SELECT name, category_id
        FROM category) AS c ON c.category_id = fc.category_id
   GROUP BY fc.category_id
   ORDER BY count
   ")
```
From the SQL table above we can see that the result is the same as before

#Part c:
Identify which country or countries have exactly 13 customers.

Using data.frame operations after pulling required tables using SQL:
```{r}
countries<-gg(movies,"
   SELECT country_id, country
   FROM country
   ")

cust<-gg(movies,"
   SELECT customer_id, store_id, address_id
   FROM customer
   ")

address<-gg(movies,"
   SELECT address_id, city_id
   FROM address
   ")

city<-gg(movies,"
   SELECT city_id,country_id
   FROM city
   ")

mcust<-merge(cust,address,by="address_id")
mcust2<-merge(mcust,city,by="city_id")
mcust3<-merge(mcust2,countries,by="country_id")
ct_by_country<-as.data.frame(table(mcust3$country))
ct_by_country[ct_by_country$Freq==13,]
```
From the data frame above we can see that the countries where the number of customers is exactly equal to 13 is Argentina and Nigeria


Using only SQL:
```{r}
gg(movies,"
   SELECT cou.country, count(cus.customer_id) AS count
    FROM country AS cou
   RIGHT JOIN(
      SELECT city_id,country_id
        FROM city
   ) AS ci ON ci.country_id = cou.country_id
   RIGHT JOIN(
      SELECT address_id, city_id
        FROM address
   ) AS ad ON ad.city_id = ci.city_id
   RIGHT JOIN(
      SELECT *
        FROM customer
   ) AS cus ON cus.address_id = ad.address_id
   GROUP BY cou.country
   HAVING count = 13
   ")


```
From the above data frame we can see that we got the same answer as before where Argentina and Nigeria are the two countries where the number of customers is eaxtly equal to 13

##Question 3:

Downloading data
```{r}
us<-read.csv("/Users/nicholaskim/Documents/STAT 506/HW3/us-500.csv")
```

#Part a:
What proportion of email addresses are hosted at a domain with TLD “.com”?
```{r}
com<-length(us[endsWith(us$email,".com"),11])
tTLD<-nrow(us)

(com/tTLD)*100
```
From above we can see that proportion of emails that end in the domain ".com" is 73.2%

#Part b: 
What proportion of email addresses have at least one non alphanumeric character in them? 
(Excluding the required “@” and “.” found in every email address.)
```{r}
#Will extract string to characters b/f @ since anything after wont have an alpha numeric
us$bf_at <- sub("\\@.*", "", us$email)

#This will extract rows where there is an alphanumeric in the string 
has_alphanum<-us[grepl("[^a-zA-Z0-9]", us$bf_at),11]

(length(has_alphanum)/nrow(us))*100
```
From the output above we can see that the proportion of emails with an alpha numeric in its email (excluding @ and .) is 50.6%

#Part c:
What are the top 5 most common area codes amongst all phone numbers?
```{r}
area_codes<-as.data.frame(table(substr(us$phone1, 0, 3)))
area_codes[order(area_codes$Freq,decreasing=TRUE)[1:5],]
```
From the table above we can see that the 5 most common area codes are 973, 212, 215, 410, 201, respectively. 

#Part d:
Produce a histogram of the log of the apartment numbers for all addresses. (You may assume any number at the end of the an address is an apartment number.)
```{r}
#Reducing the dataset to just addresses with #. Should be addresses associated with an apartment 
ap<-us[grepl("#",us$address),4]

#Now will reduce the address string to just the apartment number. Number after #
ap_num<-sub(".*#","",ap)

hist(log(as.numeric(ap_num)),main="Histogram of the Log of Apartment Numbers",xlab="Log of Apartment Numbers")
```

#Part e:
Benford’s law is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford’s law. Do you think the apartment numbers would pass as real data?

From the plot above we can see that it doesn't seem to follow Benford's Law as the first number isn't the most frequent. Thus we can say that the apartment numbers won't pass as real data. 

